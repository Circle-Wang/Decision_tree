{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd09afc2b4a137c1ef260a208b8b14dcafe0c511635e698b6a7b46f192005b0a3f6",
   "display_name": "Python 3.8.6 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "9afc2b4a137c1ef260a208b8b14dcafe0c511635e698b6a7b46f192005b0a3f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "print(1)"
   ]
  },
  {
   "source": [
    "data = pd.read_csv(\"Bidding.csv\")[['Bidding_Ratio','Early_Bidding','Class']]\n",
    "data\n",
    "print(inforgain(data, 'Bidding_Ratio', 'Class'))\n",
    "print(inforgain(data, 'Early_Bidding', 'Class'))"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "data = pd.read_csv(\"Bidding.csv\")[['Bidding_Ratio','Early_Bidding','Class']]\n",
    "data\n",
    "choose_best_col(data,\"Class\")"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 第四版回归决策树"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ID3Tree:\n",
    "    class Node: \n",
    "        def __init__(self, name, type_node):\n",
    "            self.name = name\n",
    "            self.left = None\n",
    "            self.right = None\n",
    "            self.type = type_node\n",
    "            self.key = None\n",
    "    \n",
    "    def __init__(self):\n",
    "        None\n",
    "\n",
    "    \n",
    "    # label需要是DataFrame\n",
    "    def fit(self, data, label, largest_layer = 5):\n",
    "        self.data = pd.concat([data, label], axis=1)\n",
    "        self.columns = list(self.data.columns)\n",
    "        self.label = label.columns[0]\n",
    "        self.largest_layer = largest_layer\n",
    "        self.root = self.buildtree(self.data, 1)\n",
    "        # self.print_tree(self.root)\n",
    "        \n",
    "    # 打印树\n",
    "    def print_tree(self, root):\n",
    "        if root.type == \"leaf\":\n",
    "            print(\"leaf节点,预测值为{name}\".format(name = root.name))\n",
    "            return\n",
    "        else: \n",
    "            print(\"root节点,划分属性为{name},划分值为{key}\".format(name = root.name, key = root.key))\n",
    "        self.print_tree(root.left)\n",
    "        self.print_tree(root.right)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # ele为标签列表\n",
    "    def entropy(self, ele):    \n",
    "        probs = [ele.count(i)/len(ele) for i in set(ele)]    #计算ele集合中k类样本分布\n",
    "        entropy = -sum([prob*log(prob, 2) for prob in probs])  #计算 \n",
    "        return entropy\n",
    "\n",
    "    # data需要包含标签列\n",
    "    def inforgain(self, df, column):\n",
    "        entropy_D = self.entropy(df[self.label].tolist())\n",
    "        # 得到划分点的集合\n",
    "        valuelist = list(set(data[column].tolist()))\n",
    "        valuelist.sort()\n",
    "        Ta = []\n",
    "        for i in range(len(valuelist)-1):\n",
    "            Ta.append((valuelist[i] + valuelist[i+1])/2)\n",
    "        # 对不同划分方式依次计算其熵\n",
    "        best_gain = -999\n",
    "        for split_value in Ta:\n",
    "            D1 = df[df[column] <= split_value]\n",
    "            D2 = df[df[column] > split_value]\n",
    "            entropy_D1 = self.entropy(D1[self.label].tolist())\n",
    "            entropy_D2 = self.entropy(D2[self.label].tolist())\n",
    "            entropy_DA = len(D1)/len(df) * entropy_D1 + len(D2)/len(df) * entropy_D2\n",
    "            gain = entropy_D - entropy_DA\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_split_value = split_value\n",
    "        # 返回信息增益, 最佳分割的值\n",
    "        return best_gain , best_split_value\n",
    "\n",
    "    def choose_best_col(self, df):\n",
    "        columns = [i for i in list(df.columns) if i != self.label ]\n",
    "        best_gain, best_col_key, best_col= -99, -99, None\n",
    "        for col in columns:\n",
    "            col_gain, col_key = self.inforgain(df, col)\n",
    "            if col_gain > best_gain:\n",
    "                best_gain = col_gain\n",
    "                best_col_key = col_key\n",
    "                best_col = col\n",
    "        return best_col, best_col_key\n",
    "    \n",
    "    # 递归调用函数\n",
    "    # input_data需要包含标签列, k表示当前节点所在层数\n",
    "    def buildtree(self, input_data, k):\n",
    "        # 如果大于最大层数\n",
    "        if k >= self.largest_layer:\n",
    "            leafnode = self.Node(np.mean(input_data[self.label]), \"leaf\") #叶节点\n",
    "            return leafnode\n",
    "\n",
    "        # 若df中只有一种类型则该节点变为叶节点\n",
    "        if len(input_data[self.label].unique()) == 1:\n",
    "            leafnode = self.Node(input_data[self.label].unique()[0], \"leaf\") #叶节点     \n",
    "            return leafnode\n",
    "            \n",
    "        # 当df中所有属性的值都是一样\n",
    "        if (input_data.drop(columns = self.label).duplicated().sum() == (len(input_data)-1)):\n",
    "            leafnode = self.Node(np.mean(input_data[self.label]), \"leaf\") #叶节点\n",
    "            return leafnode\n",
    "\n",
    "        best_col, best_col_key = self.choose_best_col(input_data)\n",
    "        node = self.Node(best_col, \"root\")\n",
    "        node.key = best_col_key\n",
    "        node.left = self.buildtree(input_data[input_data[best_col] <= best_col_key], k+1)\n",
    "        node.right = self.buildtree(input_data[input_data[best_col] > best_col_key], k+1)\n",
    "        return node\n",
    "\n",
    "    def predictSingle(self, sample, node):\n",
    "        if node.type == \"leaf\":\n",
    "            return node.name\n",
    "        value = sample[node.name].values[0]\n",
    "        if value <= node.key:\n",
    "            nextNode = node.left\n",
    "            return self.predictSingle(sample, nextNode)\n",
    "        else:\n",
    "            nextNode = node.right\n",
    "            return self.predictSingle(sample, nextNode)\n",
    "\n",
    "    def predictDf(self, data):\n",
    "        prediction = []\n",
    "        for i in range(len(data)) :\n",
    "            sample = data[i:(i+1)]\n",
    "            prediction.append(self.predictSingle(sample, self.root))\n",
    "        return prediction"
   ]
  },
  {
   "source": [
    "## 测试"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root节点,划分属性为Bidding_Ratio,划分值为0.1297335205\nroot节点,划分属性为Early_Bidding,划分值为0.863606096\nleaf节点,预测值为0\nroot节点,划分属性为Early_Bidding,划分值为0.868650463\nleaf节点,预测值为1\nroot节点,划分属性为Bidding_Ratio,划分值为0.065942029\nleaf节点,预测值为0\nroot节点,划分属性为Bidding_Ratio,划分值为0.07504690450000001\nleaf节点,预测值为1.0\nleaf节点,预测值为0.0\nroot节点,划分属性为Early_Bidding,划分值为0.0017048609999999998\nleaf节点,预测值为0\nroot节点,划分属性为Bidding_Ratio,划分值为0.3397435895\nroot节点,划分属性为Early_Bidding,划分值为0.0137843915\nleaf节点,预测值为0\nroot节点,划分属性为Bidding_Ratio,划分值为0.13397129149999998\nleaf节点,预测值为1.0\nleaf节点,预测值为0.2857142857142857\nroot节点,划分属性为Bidding_Ratio,划分值为0.4083333335\nroot节点,划分属性为Bidding_Ratio,划分值为0.3660714285\nleaf节点,预测值为1.0\nleaf节点,预测值为0.0\nleaf节点,预测值为1\n[0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0]\n[0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "tree = ID3Tree()\n",
    "data = pd.read_csv(\"Bidding.csv\")[['Bidding_Ratio','Early_Bidding']][1:300]\n",
    "label = pd.read_csv(\"Bidding.csv\")[[\"Class\"]][1:300]\n",
    "test = pd.read_csv(\"Bidding.csv\")[['Bidding_Ratio','Early_Bidding']][301:311]\n",
    "test_label = pd.read_csv(\"Bidding.csv\")[[\"Class\"]][301:311]\n",
    "tree.fit(data,label, 6)\n",
    "print(tree.predictDf(test))\n",
    "print(test_label.values.squeeze())"
   ]
  },
  {
   "source": [
    "## 交叉验证"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root节点,划分属性为Bidding_Ratio,划分值为0.1297335205\n",
      "root节点,划分属性为Early_Bidding,划分值为0.863606096\n",
      "leaf节点,预测值为0\n",
      "root节点,划分属性为Early_Bidding,划分值为0.868650463\n",
      "leaf节点,预测值为1\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.065942029\n",
      "leaf节点,预测值为0.0\n",
      "leaf节点,预测值为0.07142857142857142\n",
      "root节点,划分属性为Early_Bidding,划分值为0.0017048609999999998\n",
      "leaf节点,预测值为0\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.3397435895\n",
      "root节点,划分属性为Early_Bidding,划分值为0.0137843915\n",
      "leaf节点,预测值为0.0\n",
      "leaf节点,预测值为0.3076923076923077\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.4083333335\n",
      "leaf节点,预测值为0.6666666666666666\n",
      "leaf节点,预测值为1.0\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.1297335205\n",
      "root节点,划分属性为Early_Bidding,划分值为0.863606096\n",
      "leaf节点,预测值为0\n",
      "root节点,划分属性为Early_Bidding,划分值为0.868650463\n",
      "leaf节点,预测值为1\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.065942029\n",
      "leaf节点,预测值为0.0\n",
      "leaf节点,预测值为0.08333333333333333\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.4083333335\n",
      "root节点,划分属性为Early_Bidding,划分值为0.0568650795\n",
      "leaf节点,预测值为0\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.13397129149999998\n",
      "leaf节点,预测值为1.0\n",
      "leaf节点,预测值为0.29411764705882354\n",
      "root节点,划分属性为Early_Bidding,划分值为6.48e-05\n",
      "leaf节点,预测值为0\n",
      "leaf节点,预测值为1\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.1297335205\n",
      "root节点,划分属性为Early_Bidding,划分值为0.863606096\n",
      "leaf节点,预测值为0\n",
      "root节点,划分属性为Early_Bidding,划分值为0.868650463\n",
      "leaf节点,预测值为1\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.065942029\n",
      "leaf节点,预测值为0.0\n",
      "leaf节点,预测值为0.09090909090909091\n",
      "root节点,划分属性为Early_Bidding,划分值为0.0017048609999999998\n",
      "leaf节点,预测值为0\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.4083333335\n",
      "root节点,划分属性为Early_Bidding,划分值为0.019041832\n",
      "leaf节点,预测值为0.0\n",
      "leaf节点,预测值为0.3333333333333333\n",
      "leaf节点,预测值为1\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.1297335205\n",
      "root节点,划分属性为Early_Bidding,划分值为0.863606096\n",
      "leaf节点,预测值为0\n",
      "root节点,划分属性为Early_Bidding,划分值为0.868650463\n",
      "leaf节点,预测值为1\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.065942029\n",
      "leaf节点,预测值为0.0\n",
      "leaf节点,预测值为0.07142857142857142\n",
      "root节点,划分属性为Early_Bidding,划分值为0.0137843915\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.6125\n",
      "leaf节点,预测值为0\n",
      "leaf节点,预测值为1\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.3397435895\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.13397129149999998\n",
      "leaf节点,预测值为1.0\n",
      "leaf节点,预测值为0.29310344827586204\n",
      "root节点,划分属性为Early_Bidding,划分值为0.019041832\n",
      "leaf节点,预测值为0.5\n",
      "leaf节点,预测值为1.0\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.1297335205\n",
      "root节点,划分属性为Early_Bidding,划分值为0.863606096\n",
      "leaf节点,预测值为0\n",
      "root节点,划分属性为Early_Bidding,划分值为0.868650463\n",
      "leaf节点,预测值为1\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.065942029\n",
      "leaf节点,预测值为0.0\n",
      "leaf节点,预测值为0.07692307692307693\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.3397435895\n",
      "root节点,划分属性为Early_Bidding,划分值为0.0137843915\n",
      "leaf节点,预测值为0\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.13397129149999998\n",
      "leaf节点,预测值为1.0\n",
      "leaf节点,预测值为0.3018867924528302\n",
      "root节点,划分属性为Early_Bidding,划分值为0.14152391949999998\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.4083333335\n",
      "leaf节点,预测值为0.0\n",
      "leaf节点,预测值为0.8\n",
      "leaf节点,预测值为1\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.1297335205\n",
      "root节点,划分属性为Early_Bidding,划分值为0.863606096\n",
      "leaf节点,预测值为0\n",
      "root节点,划分属性为Early_Bidding,划分值为0.868650463\n",
      "leaf节点,预测值为1\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.065942029\n",
      "leaf节点,预测值为0.0\n",
      "leaf节点,预测值为0.07142857142857142\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.4083333335\n",
      "root节点,划分属性为Early_Bidding,划分值为0.019041832\n",
      "leaf节点,预测值为0\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.13397129149999998\n",
      "leaf节点,预测值为1.0\n",
      "leaf节点,预测值为0.3225806451612903\n",
      "root节点,划分属性为Early_Bidding,划分值为6.48e-05\n",
      "leaf节点,预测值为0\n",
      "leaf节点,预测值为1\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.1297335205\n",
      "root节点,划分属性为Early_Bidding,划分值为0.863606096\n",
      "leaf节点,预测值为0\n",
      "root节点,划分属性为Early_Bidding,划分值为0.868650463\n",
      "leaf节点,预测值为1\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.065942029\n",
      "leaf节点,预测值为0.0\n",
      "leaf节点,预测值为0.09090909090909091\n",
      "root节点,划分属性为Early_Bidding,划分值为0.0137843915\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.6125\n",
      "leaf节点,预测值为0\n",
      "leaf节点,预测值为1\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.3397435895\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.13397129149999998\n",
      "leaf节点,预测值为1.0\n",
      "leaf节点,预测值为0.2833333333333333\n",
      "root节点,划分属性为Early_Bidding,划分值为0.14152391949999998\n",
      "leaf节点,预测值为0.5\n",
      "leaf节点,预测值为1.0\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.1297335205\n",
      "root节点,划分属性为Early_Bidding,划分值为0.8550429890000001\n",
      "leaf节点,预测值为0\n",
      "root节点,划分属性为Early_Bidding,划分值为0.868650463\n",
      "leaf节点,预测值为1\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.065942029\n",
      "leaf节点,预测值为0.0\n",
      "leaf节点,预测值为0.07692307692307693\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.4083333335\n",
      "root节点,划分属性为Early_Bidding,划分值为0.019041832\n",
      "leaf节点,预测值为0\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.170289855\n",
      "leaf节点,预测值为0.14814814814814814\n",
      "leaf节点,预测值为0.4722222222222222\n",
      "root节点,划分属性为Early_Bidding,划分值为6.48e-05\n",
      "leaf节点,预测值为0\n",
      "leaf节点,预测值为1\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.1297335205\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.098780488\n",
      "leaf节点,预测值为0\n",
      "root节点,划分属性为Early_Bidding,划分值为0.7535630785\n",
      "leaf节点,预测值为0\n",
      "root节点,划分属性为Early_Bidding,划分值为0.868650463\n",
      "leaf节点,预测值为1.0\n",
      "leaf节点,预测值为0.0\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.4083333335\n",
      "root节点,划分属性为Early_Bidding,划分值为0.019041832\n",
      "leaf节点,预测值为0\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.3397435895\n",
      "leaf节点,预测值为0.29310344827586204\n",
      "leaf节点,预测值为0.8\n",
      "root节点,划分属性为Early_Bidding,划分值为6.48e-05\n",
      "leaf节点,预测值为0\n",
      "leaf节点,预测值为1\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.1297335205\n",
      "root节点,划分属性为Early_Bidding,划分值为0.9396612655\n",
      "leaf节点,预测值为0\n",
      "root节点,划分属性为Early_Bidding,划分值为0.943416281\n",
      "leaf节点,预测值为1\n",
      "leaf节点,预测值为0\n",
      "root节点,划分属性为Early_Bidding,划分值为0.0137843915\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.4083333335\n",
      "leaf节点,预测值为0\n",
      "leaf节点,预测值为1\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.4083333335\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.170289855\n",
      "leaf节点,预测值为0.20689655172413793\n",
      "leaf节点,预测值为0.47368421052631576\n",
      "leaf节点,预测值为1\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.1297335205\n",
      "root节点,划分属性为Early_Bidding,划分值为0.863606096\n",
      "leaf节点,预测值为0\n",
      "root节点,划分属性为Early_Bidding,划分值为0.868650463\n",
      "leaf节点,预测值为1\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.065942029\n",
      "leaf节点,预测值为0.0\n",
      "leaf节点,预测值为0.07142857142857142\n",
      "root节点,划分属性为Early_Bidding,划分值为0.0017048609999999998\n",
      "leaf节点,预测值为0\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.3397435895\n",
      "root节点,划分属性为Early_Bidding,划分值为0.0137843915\n",
      "leaf节点,预测值为0.0\n",
      "leaf节点,预测值为0.3157894736842105\n",
      "root节点,划分属性为Bidding_Ratio,划分值为0.4083333335\n",
      "leaf节点,预测值为0.6666666666666666\n",
      "leaf节点,预测值为1.0\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Data      NMSE\n",
       "0  Train  0.534552\n",
       "1   Test  0.774758"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Data</th>\n      <th>NMSE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Train</td>\n      <td>0.534552</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Test</td>\n      <td>0.774758</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# y需要是数据框\n",
    "def CVR(reg,X,y,Z=10,seed=1010):\n",
    "    np.random.seed(seed)\n",
    "    # 从np.repeat(np.arange(Z), np.ceil(len(y)/Z))数组中抽取，长度为len(y)的样本，不可重复\n",
    "    m = np.random.choice(np.repeat(np.arange(Z), np.ceil(len(y)/Z)), len(y), replace=False)\n",
    "    p0 = np.ones(len(y))\n",
    "    pcv= np.ones(len(y))\n",
    "    p0 = reg.fit(X,y)\n",
    "    p0 = reg.predictDf(X) #模型预测值\n",
    "    NMSE0 = np.sum((p0-y.values.squeeze())**2)/np.sum((np.mean(y.values.squeeze())-y.values.squeeze())**2)\n",
    "    for i in range(Z):\n",
    "        pcv[m == i] = reg.fit(X[m != i], y[m != i])\n",
    "        pcv[m == i] = reg.predictDf(X[m == i]) # pcv[m==i]的长度是len(y)/Z\n",
    "        NMSEcv=np.sum((pcv-y.values.squeeze())**2)/np.sum((np.mean(y.values.squeeze())-y.values.squeeze())**2)\n",
    "    return pd.DataFrame({\"Data\":[\"Train\",\"Test\"],\"NMSE\": [NMSE0, NMSEcv]})\n",
    "    \n",
    "a = ID3Tree()\n",
    "CVR(a, data, label)\n"
   ]
  },
  {
   "source": [
    "# 第二版决策树"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "class ID3Tree:    \n",
    "    # 定义多分支节点：属性为节点名，下属节点用字典表示(字典的键表示当前节点的属性值，值是按照该属性值划分后得到的下一节点)\n",
    "    class Node:        \n",
    "        def __init__(self, name):\n",
    "            self.name = name\n",
    "            self.connections = {}    \n",
    "        # 建立连接，增加一个叫label为键(name的属性值)，node为值的键值对\n",
    "        def connect(self, label, node):\n",
    "            self.connections[label] = node    \n",
    "    \n",
    "    # label指的是列名\n",
    "    def __init__(self, data, label):\n",
    "        self.columns = list(data.columns)\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.root = self.Node(\"Root\")    \n",
    "    \n",
    "    # 打印树\n",
    "    def print_tree(self, node, tabs):\n",
    "        print(tabs + node.name)        \n",
    "        for connection, child_node in node.connections.items():\n",
    "            print(tabs + \"\\t\" +\"(\" + str(connection) + \")\")#tabs + \"\\t\" + \n",
    "            self.print_tree(child_node, tabs + \"\\t\\t\")   \n",
    "\n",
    "    # 得到分支数据集，根据在全数据框col(属性)中出现的数值，每个数值(属性值)得到一个数据集\n",
    "    def split_dataframe(self, split_data, col):    \n",
    "        unique_values = self.data[col].unique()    #得到col列中有哪些数值\n",
    "        # 创建分类字典\n",
    "        result_dict = {elem : pd.DataFrame() for elem in unique_values}   \n",
    "        # 根据列值分割数据框,如果没有分割值则为空\n",
    "        for key in split_data[col].unique():\n",
    "            result_dict[key] = split_data[:][split_data[col] == key].drop(columns=[col])\n",
    "        # result_dict中键是col列中的数值，值是一个df(是原数据col列的值是键的所有行组成的，不包括col列)\n",
    "        return result_dict\n",
    "\n",
    "\n",
    "    # 找到给定一个df,找到最佳的列(属性).label指定df中那一列是标签\n",
    "    # 将会返回：在当前给定的样本集合下,最大信息增益，最佳划分属性(列名)，划分之后的子集合字典\n",
    "    def choose_best_col(self, df, label): \n",
    "        # 当前集合信息熵\n",
    "        entropy_D = entropy(df[label].tolist())    \n",
    "        # 得到列名，除了标签那一列, 可能会返回[]\n",
    "        cols = [col for col in df.columns if col not in [label]]    \n",
    "        # 初始化:最大信息增益，最佳列(属性)和最佳拆分字典\n",
    "        max_value, best_col = -999, None\n",
    "        max_splited = None\n",
    "\n",
    "        # 根据不同的列拆分数据\n",
    "        for col in cols:\n",
    "            splited_set = self.split_dataframe(df, col)\n",
    "            entropy_DA = 0\n",
    "\n",
    "            # 每次取出键(属性值)和值(df包括有lable列) \n",
    "            for subset_col, subset in splited_set.items():\n",
    "                if subset.empty == True:\n",
    "                    continue\n",
    "                # 计算熵\n",
    "                entropy_Di = entropy(subset[label].tolist())            \n",
    "                # 计算出如果以当前(列)属性为划分,则信息熵为\n",
    "                entropy_DA += len(subset)/len(df) * entropy_Di\n",
    "\n",
    "            # 计算出如果以当前(列)属性为划分,则信息增益为\n",
    "            info_gain = entropy_D - entropy_DA\n",
    "\n",
    "            if info_gain > max_value:\n",
    "                max_value, best_col = info_gain, col\n",
    "                max_splited = splited_set  \n",
    "        # 对每一个col都检测一遍之后就可以得知哪一个是最佳划分属性了\n",
    "        # 得到最佳划分属性名，以及以该属性\n",
    "        return best_col, max_splited\n",
    "\n",
    "\n",
    "\n",
    "    # 由根节点构建树构建树\n",
    "    def construct_tree(self):\n",
    "        self.root.connect(\"\", self.construct(self.root, self.data, self.columns))\n",
    "        self.print_tree(self.root, \"-\")\n",
    "    \n",
    "    # 构建树的递归函数\n",
    "    # 参数包括父节点，input_data(包括标签列)，剩余属性值(包括标签列)\n",
    "    def construct(self, parent_node, input_data, columns): \n",
    "\n",
    "        # 若df中只有一种类型则该节点变为叶节点\n",
    "        if len(input_data[self.label].unique()) == 1:\n",
    "            leafnode = self.Node(input_data[self.label].unique()[0]) #叶节点           \n",
    "            return leafnode\n",
    "\n",
    "        if (columns == [self.label]) or (input_data.drop(columns = self.label).duplicated().sum() == (len(input_data)-1)):\n",
    "            input_data_label_list = input_data[self.label].tolist()\n",
    "            leafnode = self.Node(max(input_data_label_list, key = input_data_label_list.count)) #叶节点\n",
    "            return leafnode\n",
    "\n",
    "\n",
    "        # 找到当前最合适的列\n",
    "        best_col, max_splited = self.choose_best_col(input_data[columns], self.label) \n",
    "        # 得到最优划分属性\n",
    "        node = self.Node(best_col)                                  #根节点\n",
    "        new_columns = [col for col in columns if col != best_col]  #剩余属性 \n",
    "\n",
    "        # 递归构造决策树\n",
    "        for splited_value, splited_data in max_splited.items():\n",
    "            if splited_data.empty == True :\n",
    "                input_data_label_list = input_data[self.label].tolist()\n",
    "                leafnode = self.Node(max(input_data_label_list, key = input_data_label_list.count)) #叶节点\n",
    "                node.connect(splited_value, leafnode)\n",
    "                continue\n",
    "            node.connect(splited_value, self.construct(node, splited_data, new_columns))\n",
    "        return node\n",
    "            \n",
    "\n",
    "    def predictSingle(self, sample, node):\n",
    "        # 如果来到叶节点就返回预测值\n",
    "        if node.name in (self.data[self.label].tolist()):\n",
    "            return node.name\n",
    "        value = sample[node.name].values[0]       #取得值\n",
    "        nextNode = node.connections[value]        #得到下一个节点\n",
    "        prediction = self.predictSingle(sample, nextNode)\n",
    "        return prediction\n",
    "    \n",
    "    def predictDf(self, data):\n",
    "        prediction = []\n",
    "        for i in range(len(data)) :\n",
    "            sample = data[i:(i+1)]\n",
    "            prediction.append(self.predictSingle(sample, self.root.connections[\"\"]))\n",
    "        return prediction\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "    data =  [[0, 0, 0, 0, 'no'],         #数据集\n",
    "            [0, 0, 0, 1, 'no'],\n",
    "            [0, 1, 0, 1, 'yes'],\n",
    "            [0, 1, 1, 0, 'yes'],\n",
    "            [0, 0, 0, 0, 'no'],\n",
    "            [1, 0, 0, 0, 'no'],\n",
    "            [1, 0, 0, 1, 'no'],\n",
    "            [1, 1, 1, 1, 'yes'],\n",
    "            [1, 0, 1, 2, 'yes'],\n",
    "            [1, 0, 1, 2, 'yes'],\n",
    "            [2, 0, 1, 2, 'yes'],\n",
    "            [2, 0, 1, 1, 'yes'],\n",
    "            [2, 1, 0, 1, 'yes'],\n",
    "            [2, 1, 0, 2, 'yes'],\n",
    "            [1, 0, 0, 2, 'no'],\n",
    "            [2, 0, 0, 0, 'yes'],\n",
    "            [0, 1, 0, 1, 'no'],\n",
    "            [0, 1, 0, 2, 'yes'],\n",
    "            [0, 1, 0, 1, 'no'],\n",
    "            [0, 0, 1, 2, 'yes'],\n",
    "            [2, 1, 0, 0, 'no'],\n",
    "            [0, 0, 1, 1, 'yes'],\n",
    "            [2, 1, 0, 2, 'no'],\n",
    "            [1, 0, 0, 2, 'yes'],\n",
    "            [1, 0, 1, 0, 'no']]\n",
    "    data = pd.DataFrame(data, columns=['年龄', '有工作', '有自己的房子', '信贷情况', '类别'])\n",
    "    decisionTree = ID3Tree(data, \"类别\")\n",
    "    decisionTree.construct_tree()"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "    testdata =  [[2, 1, 0, 2],\n",
    "                [1, 0, 1, 2],\n",
    "                [0, 0, 0, 0],\n",
    "                [1, 0, 0, 2],\n",
    "                [0, 0, 1, 2],\n",
    "                [0, 1, 0, 0],\n",
    "                [0, 1, 0, 1],\n",
    "                [2, 1, 0, 0],\n",
    "                [1, 1, 0, 2],\n",
    "                [2, 0, 0, 1]]\n",
    "    testdata = pd.DataFrame(testdata, columns=['年龄', '有工作', '有自己的房子', '信贷情况'])\n",
    "    decisionTree.predictDf(testdata)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 第三版决策树"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算熵，ele是标签集合[1,2,1,2,3,1,3,2,2,1,2]\n",
    "def entropy(ele):    \n",
    "    probs = [ele.count(i)/len(ele) for i in set(ele)]    #计算ele集合中k类样本分布\n",
    "    entropy = -sum([prob*log(prob, 2) for prob in probs])  #计算 \n",
    "    return entropy\n",
    "    \n",
    "class ID3Tree:\n",
    "    # 定义多分支节点：属性为节点名，下属节点用字典表示(字典的键表示当前节点的属性值，值是按照该属性值划分后得到的下一节点)\n",
    "    class Node:        \n",
    "        def __init__(self, name):\n",
    "            self.name = name\n",
    "            self.connections = {}    \n",
    "        # 建立连接，增加一个叫label为键(name的属性值)，node为值的键值对\n",
    "        def connect(self, label, node):\n",
    "            self.connections[label] = node    \n",
    "    \n",
    "\n",
    "    def __init__(self):\n",
    "        self.root = self.Node(\"Root\")\n",
    "\n",
    "    \n",
    "    # 打印树\n",
    "    def print_tree(self, node, tabs):\n",
    "        print(tabs + str(node.name))        \n",
    "        for connection, child_node in node.connections.items():\n",
    "            print(tabs + \"\\t\" +\"(\" + str(connection) + \")\")#tabs + \"\\t\" + \n",
    "            self.print_tree(child_node, tabs + \"\\t\\t\")   \n",
    "\n",
    "    # 得到分支数据集，根据在全数据框col(属性)中出现的数值，每个数值(属性值)得到一个数据集\n",
    "    def split_dataframe(self, split_data, col):    \n",
    "        unique_values = self.data[col].unique()    #得到col列中有哪些数值\n",
    "        # 创建分类字典\n",
    "        result_dict = {elem : pd.DataFrame() for elem in unique_values}   \n",
    "        # 根据列值分割数据框,如果没有分割值则为空\n",
    "        for key in split_data[col].unique():\n",
    "            result_dict[key] = split_data[:][split_data[col] == key].drop(columns=[col])\n",
    "        # result_dict中键是col列中的数值，值是一个df(是原数据col列的值是键的所有行组成的，不包括col列)\n",
    "        return result_dict\n",
    "\n",
    "\n",
    "    # 找到给定一个df,找到最佳的列(属性).label指定df中那一列是标签\n",
    "    # 将会返回：在当前给定的样本集合下,最大信息增益，最佳划分属性(列名)，划分之后的子集合字典\n",
    "    def choose_best_col(self, df, label): \n",
    "        # 当前集合信息熵\n",
    "        entropy_D = entropy(df[label].tolist())    \n",
    "        # 得到列名，除了标签那一列, 可能会返回[]\n",
    "        cols = [col for col in df.columns if col not in [label]]    \n",
    "        # 初始化:最大信息增益，最佳列(属性)和最佳拆分字典\n",
    "        max_value, best_col = -999, None\n",
    "        max_splited = None\n",
    "\n",
    "        # 根据不同的列拆分数据\n",
    "        for col in cols:\n",
    "            splited_set = self.split_dataframe(df, col)\n",
    "            entropy_DA = 0\n",
    "\n",
    "            # 每次取出键(属性值)和值(df包括有lable列) \n",
    "            for subset_col, subset in splited_set.items():\n",
    "                if subset.empty == True:\n",
    "                    continue\n",
    "                # 计算熵\n",
    "                entropy_Di = entropy(subset[label].tolist())            \n",
    "                # 计算出如果以当前(列)属性为划分,则信息熵为\n",
    "                entropy_DA += len(subset)/len(df) * entropy_Di\n",
    "\n",
    "            # 计算出如果以当前(列)属性为划分,则信息增益为\n",
    "            info_gain = entropy_D - entropy_DA\n",
    "\n",
    "            if info_gain > max_value:\n",
    "                max_value, best_col = info_gain, col\n",
    "                max_splited = splited_set  \n",
    "        # 对每一个col都检测一遍之后就可以得知哪一个是最佳划分属性了\n",
    "        # 得到最佳划分属性名，以及以该属性\n",
    "        return best_col, max_splited\n",
    "\n",
    "\n",
    "\n",
    "    # 由根节点构建树构建树,label必须是数据框\n",
    "    def fit(self, data, label):\n",
    "        self.data = pd.concat([data, label], axis=1)\n",
    "        self.columns = list(self.data.columns)\n",
    "        self.label = label.columns[0]\n",
    "        self.root.connect(\"\", self.construct(self.root, self.data, self.columns))\n",
    "        # self.print_tree(self.root, \"-\")\n",
    "    \n",
    "    # 树的递归函数\n",
    "    # 参数包括父节点，input_data(包括标签列)，剩余属性值(包括标签列)\n",
    "    def construct(self, parent_node, input_data, columns): \n",
    "        # 若df中只有一种类型则该节点变为叶节点\n",
    "        if len(input_data[self.label].unique()) == 1:\n",
    "            leafnode = self.Node(input_data[self.label].unique()[0]) #叶节点     \n",
    "            return leafnode\n",
    "\n",
    "        if (columns == [self.label]) or (input_data.drop(columns = self.label).duplicated().sum() == (len(input_data)-1)):\n",
    "            input_data_label_list = input_data[self.label].tolist()\n",
    "            leafnode = self.Node(max(input_data_label_list, key = input_data_label_list.count)) #叶节点\n",
    "            return leafnode\n",
    "\n",
    "\n",
    "        # 找到当前最合适的列\n",
    "        best_col, max_splited = self.choose_best_col(input_data[columns], self.label) \n",
    "        # 得到最优划分属性\n",
    "        node = self.Node(best_col)                                  #根节点\n",
    "        new_columns = [col for col in columns if col != best_col]  #剩余属性 \n",
    "\n",
    "        # 递归构造决策树\n",
    "        for splited_value, splited_data in max_splited.items():\n",
    "            if splited_data.empty == True :\n",
    "                input_data_label_list = input_data[self.label].tolist()\n",
    "                leafnode = self.Node(max(input_data_label_list, key = input_data_label_list.count)) #叶节点\n",
    "                node.connect(splited_value, leafnode)\n",
    "                continue\n",
    "            node.connect(splited_value, self.construct(node, splited_data, new_columns))\n",
    "        return node\n",
    "            \n",
    "\n",
    "    def predictSingle(self, sample, node):\n",
    "        # 如果来到叶节点就返回预测值\n",
    "        if node.name in (self.data[self.label].tolist()):\n",
    "            return node.name\n",
    "        value = sample[node.name].values[0]       #取得值\n",
    "        nextNode = node.connections[value]        #得到下一个节点\n",
    "        prediction = self.predictSingle(sample, nextNode)\n",
    "        return prediction\n",
    "    \n",
    "    def predictDf(self, data):\n",
    "        prediction = []\n",
    "        for i in range(len(data)) :\n",
    "            sample = data[i:(i+1)]\n",
    "            prediction.append(self.predictSingle(sample, self.root.connections[\"\"]))\n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =str(3)\n",
    "eval(a+\">=2\")"
   ]
  },
  {
   "source": [
    "import random\n",
    "[[random.randint(0,2), random.randint(0,1), random.randint(0,1), random.randint(0,2)] for i in range(10)]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 测试"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  [[random.randint(0,2), random.randint(0,1), random.randint(0,1), random.randint(0,2)] for i in range(10)] #构造数据集\n",
    "data = pd.DataFrame(data, columns=['年龄', '有工作', '有自己的房子', '信贷情况'])\n",
    "print(data)\n",
    "label = pd.DataFrame(np.random.choice([0,1], len(data)), columns = [\"类别\"])\n",
    "print(label)\n",
    "decisionTree = ID3Tree()\n",
    "decisionTree.fit(data, label)\n",
    "decisionTree.print_tree(decisionTree.root, \"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata =  [[2, 1, 0, 2],\n",
    "            [1, 0, 1, 2],\n",
    "            [0, 0, 0, 0],\n",
    "            [1, 0, 0, 2],\n",
    "            [0, 0, 1, 2],\n",
    "            [0, 1, 0, 0],\n",
    "            [0, 1, 0, 1],\n",
    "            [2, 1, 0, 0],\n",
    "            [1, 1, 0, 2],\n",
    "            [2, 0, 0, 1]]\n",
    "testdata = pd.DataFrame(testdata, columns=['年龄', '有工作', '有自己的房子', '信贷情况'])\n",
    "testdata.describe()"
   ]
  },
  {
   "source": [
    "## 交叉验证函数"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y需要是数据框\n",
    "def CVR(reg,X,y,Z=10,seed=1010):\n",
    "    np.random.seed(seed)\n",
    "    # 从np.repeat(np.arange(Z), np.ceil(len(y)/Z))数组中抽取，长度为len(y)的样本，不可重复\n",
    "    m = np.random.choice(np.repeat(np.arange(Z), np.ceil(len(y)/Z)), len(y), replace=False)\n",
    "    p0 = np.ones(len(y))\n",
    "    pcv= np.ones(len(y))\n",
    "    p0 = reg.fit(X,y)\n",
    "    p0 = reg.predictDf(X) #模型预测值\n",
    "    NMSE0 = np.sum((p0-y.values.squeeze())**2)/np.sum((np.mean(y.values.squeeze())-y.values.squeeze())**2)\n",
    "    for i in range(Z):\n",
    "        pcv[m == i] = reg.fit(X[m != i], y[m != i])\n",
    "        pcv[m == i] = reg.predictDf(X[m == i]) # pcv[m==i]的长度是len(y)/Z\n",
    "        NMSEcv=np.sum((pcv-y.values.squeeze())**2)/np.sum((np.mean(y.values.squeeze())-y.values.squeeze())**2)\n",
    "    return pd.DataFrame({\"Data\":[\"Train\",\"Test\"],\"NMSE\": [NMSE0, NMSEcv]})\n",
    "a = ID3Tree()\n",
    "CVR(a, data, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}